{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "from lightning import pytorch as pl\n",
                "from lightning.pytorch.callbacks import ModelCheckpoint\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "from chemprop import data, featurizers, models, nn, utils"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                                         full_smiles  rejection\n",
                        "0                               CO.N#CC1=CC=C(N)C=C1   0.260000\n",
                        "1                          CCCCCCC.COC1=CC=C(OC)C=C1  -0.033365\n",
                        "2   CC(OCC)=O.OC(CC1=C(C=CC=C1)NC2=C(C=CC=C2Cl)Cl)=O   0.143540\n",
                        "3  O.CC1(C(N2C(S1)C(C2=O)NC(=O)C(C3=CC=CC=C3)N)C(...   0.926400\n",
                        "4                                        CO.C(CBr)Br   0.111000\n"
                    ]
                }
            ],
            "source": [
                "# Define paths\n",
                "chemprop_dir = Path.cwd().parent\n",
                "input_path = chemprop_dir / \"training\" / \"data\" / \"train_smiles.csv\" \n",
                "descriptors_path = chemprop_dir / \"training\" / \"data\" / \"descriptors.csv\"\n",
                "num_workers = 0 \n",
                "smiles_column = 'full_smiles' \n",
                "target_columns = ['rejection'] \n",
                "\n",
                "# Load data\n",
                "df_input = pd.read_csv(input_path)\n",
                "print(df_input.head())\n",
                "smis = df_input.loc[:, smiles_column].values\n",
                "ys = df_input.loc[:, target_columns].values\n",
                "\n",
                "# Extract additional descriptors\n",
                "df_descriptors = pd.read_csv(descriptors_path)\n",
                "extra_mol_descriptors = np.array(df_descriptors.values)\n",
                "mols = [utils.make_mol(smi, keep_h=False, add_h=False) for smi in smis]\n",
                "\n",
                "# Define datapoints\n",
                "datapoints = [\n",
                "    data.MoleculeDatapoint(mol, y, x_d=X_d)\n",
                "    for mol, y, X_d in zip(\n",
                "        mols,\n",
                "        ys,\n",
                "        extra_mol_descriptors,\n",
                "    )\n",
                "]\n",
                "\n",
                "# Split data\n",
                "train_indices, val_indices, test_indices = data.make_split_indices(mols, \"random\", (0.8, 0.1, 0.1), num_replicates=3)  # unpack the tuple into three separate lists\n",
                "train_data, val_data, test_data = data.split_data_by_indices(\n",
                "    datapoints, train_indices, val_indices, test_indices\n",
                ")\n",
                "\n",
                "# Define data loaders\n",
                "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
                "\n",
                "train_dset = data.MoleculeDataset(train_data[0], featurizer)\n",
                "scaler = train_dset.normalize_targets()\n",
                "extra_mol_descriptors_scaler = train_dset.normalize_inputs(\"X_d\")\n",
                "\n",
                "val_dset = data.MoleculeDataset(val_data[0], featurizer)\n",
                "val_dset.normalize_targets(scaler)\n",
                "val_dset.normalize_inputs(\"X_d\", extra_mol_descriptors_scaler)\n",
                "\n",
                "test_dset = data.MoleculeDataset(test_data[0], featurizer)\n",
                "\n",
                "train_loader = data.build_dataloader(train_dset, num_workers=num_workers)\n",
                "val_loader = data.build_dataloader(val_dset, num_workers=num_workers, shuffle=False)\n",
                "test_loader = data.build_dataloader(test_dset, num_workers=num_workers, shuffle=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ClassRegistry {\n",
                        "    'mse': <class 'chemprop.nn.metrics.MSE'>,\n",
                        "    'mae': <class 'chemprop.nn.metrics.MAE'>,\n",
                        "    'rmse': <class 'chemprop.nn.metrics.RMSE'>,\n",
                        "    'bounded-mse': <class 'chemprop.nn.metrics.BoundedMSE'>,\n",
                        "    'bounded-mae': <class 'chemprop.nn.metrics.BoundedMAE'>,\n",
                        "    'bounded-rmse': <class 'chemprop.nn.metrics.BoundedRMSE'>,\n",
                        "    'r2': <class 'chemprop.nn.metrics.R2Score'>,\n",
                        "    'binary-mcc': <class 'chemprop.nn.metrics.BinaryMCCMetric'>,\n",
                        "    'multiclass-mcc': <class 'chemprop.nn.metrics.MulticlassMCCMetric'>,\n",
                        "    'roc': <class 'chemprop.nn.metrics.BinaryAUROC'>,\n",
                        "    'prc': <class 'chemprop.nn.metrics.BinaryAUPRC'>,\n",
                        "    'accuracy': <class 'chemprop.nn.metrics.BinaryAccuracy'>,\n",
                        "    'f1': <class 'chemprop.nn.metrics.BinaryF1Score'>\n",
                        "}\n"
                    ]
                }
            ],
            "source": [
                "# Define the model\n",
                "mp = nn.BondMessagePassing()\n",
                "agg = nn.MeanAggregation()\n",
                "ffn_input_dim = mp.output_dim + extra_mol_descriptors.shape[1]\n",
                "output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)\n",
                "ffn = nn.RegressionFFN(n_layers=2, input_dim=ffn_input_dim, output_transform=output_transform, dropout=0.5)\n",
                "batch_norm = True\n",
                "print(nn.metrics.MetricRegistry)\n",
                "metric_list = [nn.metrics.RMSE(), nn.metrics.R2Score()] # Only the first metric is used for training and early stopping\n",
                "\n",
                "X_d_transform = nn.ScaleTransform.from_standard_scaler(extra_mol_descriptors_scaler)\n",
                "\n",
                "ensemble = []\n",
                "n_models = 3\n",
                "for _ in range(n_models):\n",
                "    ensemble.append(models.MPNN(mp, agg, ffn, metric_list, X_d_transform=X_d_transform))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: True (mps), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "GPU available: True (mps), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "GPU available: True (mps), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "/opt/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /Users/rossom/Desktop/Projects/nf10k/project_notebooks/training/model/checkpoints exists and is not empty.\n",
                        "Loading `train_dataloader` to estimate number of stepping batches.\n",
                        "/opt/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=13` in the `DataLoader` to improve performance.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
                            "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name            </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
                            "┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ message_passing │ BondMessagePassing │  227 K │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ agg             │ MeanAggregation    │      0 │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ bn              │ BatchNorm1d        │    600 │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ predictor       │ RegressionFFN      │  212 K │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ X_d_transform   │ ScaleTransform     │      0 │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ metrics         │ ModuleList         │      0 │ train │     0 │\n",
                            "└───┴─────────────────┴────────────────────┴────────┴───────┴───────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
                            "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName           \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
                            "┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
                            "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ message_passing │ BondMessagePassing │  227 K │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ agg             │ MeanAggregation    │      0 │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ bn              │ BatchNorm1d        │    600 │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ predictor       │ RegressionFFN      │  212 K │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ X_d_transform   │ ScaleTransform     │      0 │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ metrics         │ ModuleList         │      0 │ train │     0 │\n",
                            "└───┴─────────────────┴────────────────────┴────────┴───────┴───────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 441 K                                                                                            \n",
                            "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
                            "<span style=\"font-weight: bold\">Total params</span>: 441 K                                                                                                \n",
                            "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
                            "<span style=\"font-weight: bold\">Modules in train mode</span>: 26                                                                                          \n",
                            "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
                            "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1mTrainable params\u001b[0m: 441 K                                                                                            \n",
                            "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
                            "\u001b[1mTotal params\u001b[0m: 441 K                                                                                                \n",
                            "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n",
                            "\u001b[1mModules in train mode\u001b[0m: 26                                                                                          \n",
                            "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
                            "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/anaconda3/envs/chemprop/lib/python3.11/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
                            "Jupyter support\n",
                            "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "/opt/anaconda3/envs/chemprop/lib/python3.11/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
                            "Jupyter support\n",
                            "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:43\n",
                            "4: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
                            "`num_workers` argument` to `num_workers=13` in the `DataLoader` to improve performance.\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "/opt/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:43\n",
                            "4: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
                            "`num_workers` argument` to `num_workers=13` in the `DataLoader` to improve performance.\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/core/saving.py:365: Skipping 'batch_norm' parameter because it is not possible to safely dump to YAML.\n",
                        "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                        ],
                        "text/plain": []
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading `train_dataloader` to estimate number of stepping batches.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
                            "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name            </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
                            "┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ message_passing │ BondMessagePassing │  227 K │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ agg             │ MeanAggregation    │      0 │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ bn              │ BatchNorm1d        │    600 │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ predictor       │ RegressionFFN      │  212 K │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ X_d_transform   │ ScaleTransform     │      0 │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ metrics         │ ModuleList         │      0 │ train │     0 │\n",
                            "└───┴─────────────────┴────────────────────┴────────┴───────┴───────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
                            "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName           \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
                            "┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
                            "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ message_passing │ BondMessagePassing │  227 K │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ agg             │ MeanAggregation    │      0 │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ bn              │ BatchNorm1d        │    600 │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ predictor       │ RegressionFFN      │  212 K │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ X_d_transform   │ ScaleTransform     │      0 │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ metrics         │ ModuleList         │      0 │ train │     0 │\n",
                            "└───┴─────────────────┴────────────────────┴────────┴───────┴───────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 441 K                                                                                            \n",
                            "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
                            "<span style=\"font-weight: bold\">Total params</span>: 441 K                                                                                                \n",
                            "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
                            "<span style=\"font-weight: bold\">Modules in train mode</span>: 26                                                                                          \n",
                            "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
                            "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1mTrainable params\u001b[0m: 441 K                                                                                            \n",
                            "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
                            "\u001b[1mTotal params\u001b[0m: 441 K                                                                                                \n",
                            "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n",
                            "\u001b[1mModules in train mode\u001b[0m: 26                                                                                          \n",
                            "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
                            "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                        ],
                        "text/plain": []
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading `train_dataloader` to estimate number of stepping batches.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
                            "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name            </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
                            "┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ message_passing │ BondMessagePassing │  227 K │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ agg             │ MeanAggregation    │      0 │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ bn              │ BatchNorm1d        │    600 │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ predictor       │ RegressionFFN      │  212 K │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ X_d_transform   │ ScaleTransform     │      0 │ train │     0 │\n",
                            "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ metrics         │ ModuleList         │      0 │ train │     0 │\n",
                            "└───┴─────────────────┴────────────────────┴────────┴───────┴───────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
                            "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName           \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
                            "┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
                            "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ message_passing │ BondMessagePassing │  227 K │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ agg             │ MeanAggregation    │      0 │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ bn              │ BatchNorm1d        │    600 │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ predictor       │ RegressionFFN      │  212 K │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ X_d_transform   │ ScaleTransform     │      0 │ train │     0 │\n",
                            "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ metrics         │ ModuleList         │      0 │ train │     0 │\n",
                            "└───┴─────────────────┴────────────────────┴────────┴───────┴───────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 441 K                                                                                            \n",
                            "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
                            "<span style=\"font-weight: bold\">Total params</span>: 441 K                                                                                                \n",
                            "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
                            "<span style=\"font-weight: bold\">Modules in train mode</span>: 26                                                                                          \n",
                            "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
                            "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1mTrainable params\u001b[0m: 441 K                                                                                            \n",
                            "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
                            "\u001b[1mTotal params\u001b[0m: 441 K                                                                                                \n",
                            "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n",
                            "\u001b[1mModules in train mode\u001b[0m: 26                                                                                          \n",
                            "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
                            "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                        ],
                        "text/plain": []
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Train\n",
                "# Configure model checkpointing\n",
                "checkpointing = ModelCheckpoint(\n",
                "    \"model/checkpoints\",  # Directory where model checkpoints will be saved\n",
                "    \"best-{epoch}-{val_loss:.2f}\",  # Filename format for checkpoints, including epoch and validation loss\n",
                "    \"val_loss\",  # Metric used to select the best checkpoint (based on validation loss)\n",
                "    mode=\"min\",  # Save the checkpoint with the lowest validation loss (minimization objective)\n",
                "    save_last=True,  # Always save the most recent checkpoint, even if it's not the best\n",
                ")\n",
                "\n",
                "trainers = []\n",
                "for model in ensemble:\n",
                "    trainer = pl.Trainer(\n",
                "        logger=True,\n",
                "        enable_checkpointing=True, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
                "        enable_progress_bar=True,\n",
                "        accelerator=\"auto\",\n",
                "        devices=1,\n",
                "        max_epochs=1, # number of epochs to train for\n",
                "        callbacks=[checkpointing], # Use the configured checkpoint callback\n",
                "    )\n",
                "    trainers.append(trainer)\n",
                "\n",
                "for trainer, model in zip(trainers, ensemble):\n",
                "    trainer.fit(model, train_loader, val_loader)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=13` in the `DataLoader` to improve performance.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                        ],
                        "text/plain": []
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                        ],
                        "text/plain": []
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                        ],
                        "text/plain": []
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Make predictions with the ensemble\n",
                "predictions = []\n",
                "for trainer, model in zip(trainers, ensemble):\n",
                "    predictions.append(torch.concat(trainer.predict(model, test_loader)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mean prediction: 1.1549\n",
                        "Mean uncertainty (std): 0.5864\n",
                        "Mean coefficient of variation: 0.5397\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>mean_prediction</th>\n",
                            "      <th>std_dev</th>\n",
                            "      <th>variance</th>\n",
                            "      <th>coefficient_of_variation</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1.339892</td>\n",
                            "      <td>0.570404</td>\n",
                            "      <td>0.325360</td>\n",
                            "      <td>0.425709</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0.914156</td>\n",
                            "      <td>0.457258</td>\n",
                            "      <td>0.209085</td>\n",
                            "      <td>0.500197</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1.092786</td>\n",
                            "      <td>0.577866</td>\n",
                            "      <td>0.333929</td>\n",
                            "      <td>0.528800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0.589933</td>\n",
                            "      <td>0.188326</td>\n",
                            "      <td>0.035467</td>\n",
                            "      <td>0.319232</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0.852640</td>\n",
                            "      <td>0.495163</td>\n",
                            "      <td>0.245187</td>\n",
                            "      <td>0.580741</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   mean_prediction   std_dev  variance  coefficient_of_variation\n",
                            "0         1.339892  0.570404  0.325360                  0.425709\n",
                            "1         0.914156  0.457258  0.209085                  0.500197\n",
                            "2         1.092786  0.577866  0.333929                  0.528800\n",
                            "3         0.589933  0.188326  0.035467                  0.319232\n",
                            "4         0.852640  0.495163  0.245187                  0.580741"
                        ]
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "stacked_predictions = torch.stack(predictions) # [M, N, T]\n",
                "\n",
                "# Calculate uncertainty metrics\n",
                "mean_prediction = stacked_predictions.mean(dim=0)  # Mean across models\n",
                "variance = stacked_predictions.var(dim=0)  # Variance across models (aleatoric + epistemic)\n",
                "std_dev = stacked_predictions.std(dim=0)  # Standard deviation\n",
                "\n",
                "# Total uncertainty (variance of ensemble predictions)\n",
                "total_uncertainty = variance.squeeze()\n",
                "\n",
                "# Coefficient of variation (normalized uncertainty)\n",
                "coefficient_of_variation = (std_dev / (mean_prediction.abs() + 1e-8)).squeeze()\n",
                "\n",
                "# Convert to numpy for analysis\n",
                "mean_prediction_np = mean_prediction.numpy()\n",
                "total_uncertainty_np = total_uncertainty.numpy()\n",
                "std_dev_np = std_dev.numpy()\n",
                "cv_np = coefficient_of_variation.numpy()\n",
                "\n",
                "# Display uncertainty statistics\n",
                "print(f\"Mean prediction: {mean_prediction_np.mean():.4f}\")\n",
                "print(f\"Mean uncertainty (std): {std_dev_np.mean():.4f}\")\n",
                "print(f\"Mean coefficient of variation: {cv_np.mean():.4f}\")\n",
                "\n",
                "# Create uncertainty dataframe\n",
                "uncertainty_df = pd.DataFrame({\n",
                "    'mean_prediction': mean_prediction_np.flatten(),\n",
                "    'std_dev': std_dev_np.flatten(),\n",
                "    'variance': total_uncertainty_np.flatten(),\n",
                "    'coefficient_of_variation': cv_np.flatten()\n",
                "})\n",
                "\n",
                "uncertainty_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "9920\n"
                    ]
                }
            ],
            "source": [
                "print(len(datapoints))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "chemprop",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
